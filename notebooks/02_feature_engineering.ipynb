{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba4e960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de transações...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ricardo/Projects/personal-projects/github/credit-risk-ml/notebooks/data/raw/transactions_2024.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCarregando dados de transações...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m transactions_file = os.path.join(RAW_DATA_DIR, \u001b[33m'\u001b[39m\u001b[33mtransactions_2024.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransactions_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCarregados \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m transações\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Carregar insights da EDA\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/personal-projects/github/credit-risk-ml/venv/lib/python3.12/site-packages/pandas/io/parquet.py:670\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    667\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    668\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/personal-projects/github/credit-risk-ml/venv/lib/python3.12/site-packages/pandas/io/parquet.py:265\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    263\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    272\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    273\u001b[39m         path_or_handle,\n\u001b[32m    274\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m         **kwargs,\n\u001b[32m    278\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/personal-projects/github/credit-risk-ml/venv/lib/python3.12/site-packages/pandas/io/parquet.py:139\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    129\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    131\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    132\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    143\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/personal-projects/github/credit-risk-ml/venv/lib/python3.12/site-packages/pandas/io/common.py:872\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    863\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    864\u001b[39m             handle,\n\u001b[32m    865\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    868\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    869\u001b[39m         )\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m872\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    873\u001b[39m     handles.append(handle)\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/ricardo/Projects/personal-projects/github/credit-risk-ml/notebooks/data/raw/transactions_2024.parquet'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script para corrigir o erro no notebook 02_feature_engineering.ipynb\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de plotagem\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Obter o caminho da raiz do projeto\n",
    "current_path = pathlib.Path().absolute()\n",
    "if current_path.name == 'scripts':\n",
    "    project_root = current_path.parent\n",
    "else:\n",
    "    project_root = current_path\n",
    "\n",
    "# Definir caminhos para as pastas de dados\n",
    "RAW_DATA_DIR = os.path.join(project_root, 'data', 'raw')\n",
    "PROCESSED_DATA_DIR = os.path.join(project_root, 'data', 'processed')\n",
    "\n",
    "# Garantir que as pastas existam\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Carregar Dados e Insights da EDA\n",
    "print(\"Carregando dados de transações...\")\n",
    "transactions_file = os.path.join(RAW_DATA_DIR, 'transactions_2024.parquet')\n",
    "df = pd.read_parquet(transactions_file)\n",
    "print(f\"Carregados {len(df):,} transações\")\n",
    "\n",
    "# Carregar insights da EDA\n",
    "insights_file = os.path.join(PROCESSED_DATA_DIR, 'eda_insights.json')\n",
    "with open(insights_file, 'r') as f:\n",
    "    insights = json.load(f)\n",
    "print(\"Insights da EDA carregados com sucesso!\")\n",
    "\n",
    "# Função corrigida para contar transações nas últimas 24 horas\n",
    "def count_txns_last_24h(group):\n",
    "    \"\"\"\n",
    "    Conta quantas transações foram realizadas nas últimas 24 horas para cada transação\n",
    "    \"\"\"\n",
    "    # Garantir que timestamp seja datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(group['timestamp']):\n",
    "        group['timestamp'] = pd.to_datetime(group['timestamp'])\n",
    "    \n",
    "    # Ordenar transações por timestamp\n",
    "    group = group.sort_values('timestamp')\n",
    "    timestamps = group['timestamp'].tolist()\n",
    "    counts = []\n",
    "    \n",
    "    for i, ts in enumerate(timestamps):\n",
    "        # Correção: Calcular a diferença de tempo para cada transação anterior\n",
    "        count = 0\n",
    "        for prev_ts in timestamps[:i]:\n",
    "            # Verificar se a transação anterior ocorreu nas últimas 24 horas\n",
    "            if isinstance(ts, datetime) and isinstance(prev_ts, datetime):\n",
    "                if (ts - prev_ts) <= timedelta(hours=24):\n",
    "                    count += 1\n",
    "        counts.append(count)\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# 3. Feature Engineering\n",
    "print(\"\\n=== Criando Features Temporais ===\")\n",
    "\n",
    "# Converter timestamp para datetime se necessário\n",
    "if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Extrair features temporais\n",
    "df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Visualizar distribuição de transações por hora do dia\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='hour_of_day', data=df)\n",
    "plt.title('Distribuição de Transações por Hora do Dia')\n",
    "plt.xlabel('Hora do Dia')\n",
    "plt.ylabel('Número de Transações')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Features de Velocidade\n",
    "print(\"\\n=== Criando Features de Velocidade ===\")\n",
    "print(\"Calculando transações nas últimas 24 horas por cliente...\")\n",
    "\n",
    "# Aplicar a função por cliente\n",
    "df['txn_count_24h'] = df.groupby('customer_id').apply(\n",
    "    lambda x: pd.Series(count_txns_last_24h(x), index=x.index)\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "# Feature de alta velocidade\n",
    "df['high_velocity'] = (df['txn_count_24h'] > insights['velocity_threshold']).astype(int)\n",
    "\n",
    "# 4. Features de Valor\n",
    "print(\"\\n=== Criando Features de Valor ===\")\n",
    "\n",
    "# Calcular estatísticas de valor por cliente\n",
    "customer_stats = df.groupby('customer_id')['amount'].agg(['mean', 'std', 'max']).reset_index()\n",
    "customer_stats.columns = ['customer_id', 'avg_amount', 'std_amount', 'max_amount']\n",
    "\n",
    "# Mesclar de volta ao dataframe principal\n",
    "df = pd.merge(df, customer_stats, on='customer_id', how='left')\n",
    "\n",
    "# Criar feature de valor anômalo\n",
    "df['amount_zscore'] = df.groupby('customer_id')['amount'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std() if len(x) > 1 and x.std() > 0 else 0\n",
    ")\n",
    "df['is_amount_anomaly'] = (abs(df['amount_zscore']) > insights['amount_zscore_threshold']).astype(int)\n",
    "\n",
    "# 5. Features de Localização\n",
    "print(\"\\n=== Criando Features de Localização ===\")\n",
    "\n",
    "# Calcular distância entre transações consecutivas (simplificado)\n",
    "def calculate_distance_features(group):\n",
    "    group = group.sort_values('timestamp')\n",
    "    \n",
    "    # Inicializar colunas\n",
    "    group['distance_from_prev'] = 0.0\n",
    "    group['time_since_prev'] = pd.Timedelta(seconds=0)\n",
    "    group['speed'] = 0.0\n",
    "    \n",
    "    # Calcular para cada transação após a primeira\n",
    "    for i in range(1, len(group)):\n",
    "        # Distância em km (simplificada usando coordenadas cartesianas)\n",
    "        lat1, lon1 = group.iloc[i-1]['latitude'], group.iloc[i-1]['longitude']\n",
    "        lat2, lon2 = group.iloc[i]['latitude'], group.iloc[i]['longitude']\n",
    "        \n",
    "        # Distância euclidiana aproximada (para simplificar)\n",
    "        dist = np.sqrt((lat2 - lat1)**2 + (lon2 - lon1)**2) * 111  # 1 grau ≈ 111 km\n",
    "        group.iloc[i, group.columns.get_loc('distance_from_prev')] = dist\n",
    "        \n",
    "        # Tempo desde a transação anterior\n",
    "        time_diff = group.iloc[i]['timestamp'] - group.iloc[i-1]['timestamp']\n",
    "        group.iloc[i, group.columns.get_loc('time_since_prev')] = time_diff\n",
    "        \n",
    "        # Velocidade em km/h\n",
    "        hours = time_diff.total_seconds() / 3600\n",
    "        if hours > 0:\n",
    "            speed = dist / hours\n",
    "            group.iloc[i, group.columns.get_loc('speed')] = speed\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Aplicar função por cliente\n",
    "print(\"Calculando features de distância e velocidade...\")\n",
    "df = df.groupby('customer_id').apply(calculate_distance_features).reset_index(drop=True)\n",
    "\n",
    "# Identificar transações com velocidade impossível\n",
    "df['impossible_travel'] = (df['speed'] > insights['max_possible_speed']).astype(int)\n",
    "\n",
    "# 6. Salvar Dataset Processado\n",
    "print(\"\\n=== Salvando Dataset com Features ===\")\n",
    "output_file = os.path.join(PROCESSED_DATA_DIR, 'transactions_features.parquet')\n",
    "df.to_parquet(output_file)\n",
    "print(f\"Dataset salvo em {output_file}\")\n",
    "print(f\"Total de features criadas: {df.shape[1] - 7}\")  # Subtrair as colunas originais\n",
    "\n",
    "# Mostrar as primeiras linhas do dataset com as novas features\n",
    "print(\"\\nPrimeiras linhas do dataset com as novas features:\")\n",
    "print(df.head())\n",
    "\n",
    "# Resumo das features criadas\n",
    "print(\"\\nResumo das features criadas:\")\n",
    "print(\"1. Features Temporais: hour_of_day, day_of_week, is_weekend\")\n",
    "print(\"2. Features de Velocidade: txn_count_24h, high_velocity\")\n",
    "print(\"3. Features de Valor: avg_amount, std_amount, max_amount, amount_zscore, is_amount_anomaly\")\n",
    "print(\"4. Features de Localização: distance_from_prev, time_since_prev, speed, impossible_travel\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
